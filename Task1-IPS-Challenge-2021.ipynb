{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 WiFi Similarity Introduction\n",
    "\n",
    "To get you started we've put together a simple problem to introduce some key indoor positioning concepts. Consider the following environment: a user is travelling in open space in the presence of 3 WiFi emitters (we call the data created by this user a trajectory). Each emitter has a unique mac address. The user is equipped with a smartphone that will periodically scan the WiFi environment and record the RSSI of each detected mac (in dB).\n",
    "\n",
    "For this model we have used a standard log-loss free-space propagation model for each of the emitters. This is a simplistic model that works well in free space, but breaks down in real indoor environments with walls and other obstacles which can bounce the signals around in a more complex manner. In general we do expect to see a steep drop in RSSI over distance as the fixed energy from the emitting antenna is spread over an increasing area as the wave propagates. In the diagram below each circle denotes a drop of 10dB.\n",
    "\n",
    "The user walks North-East from point (0,0) and there phone makes three scans of the environment. The data recorded at each scan is shown below.\n",
    "```\n",
    "scan 0 -> {'green': -60, 'blue': -66, 'red': -67}\n",
    "scan 1 -> {'green': -58, 'blue': -61, 'red': -60} \n",
    "scan 2 -> {'green': -66, 'blue': -62, 'red': -59}\n",
    "```\n",
    "The complex and locally unique properties of the WiFi environment make it very useful for indoor positioning systems. For example in the below image `scan 1` measures data at roughly the centroid of the three emitters and there is no other place in this environment where one could take a reading that would register similar RSSI values. Given a set of scans or \"fingerprints\" from independent trajectories, we are interested in calculating how similar they are in WiFi space as this is an indication of how close they are in real space.\n",
    "\n",
    "Your first challenge is to write a function to calculate the *Euclidean Distance* and *Manhattan Distance* metrics between each of the scans in the sample trajectory that we introduced above. Using the data from a single trajectory is a good way to test the quality of a similarity metric as we can get fairly accurate estimates of the true distance using the data from the phone's intertial measurement unit (IMU) which is used by a pedestrian dead reckoning (PDR) module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![intro_1.png](figures/intro_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(fp1, fp2):\n",
    "    s = 0\n",
    "    for k, v in fp1.items():\n",
    "        s += (fp1[k] - fp2[k])**2\n",
    "    return s**(1/2)\n",
    "\n",
    "def manhattan(fp1, fp2):\n",
    "    s = 0\n",
    "    for k, v in fp1.items():\n",
    "        s += abs(fp1[k] - fp2[k])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean Average Error\n",
      "9.29\n",
      "Manhattan Average Error\n",
      "4.90\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from metrics import eval_dist_metric\n",
    "\n",
    "with open(\"intro_trajectory_1.json\") as f:\n",
    "    traj = json.load(f)\n",
    "    \n",
    "\n",
    "## Pre-calculate the pair indexes we are interested in\n",
    "keys = []\n",
    "for fp1 in traj['fps']:\n",
    "    for fp2 in traj['fps']:\n",
    "         # only calculate the upper triangle\n",
    "        if fp1['step_index'] > fp2['step_index']:\n",
    "            keys.append((fp1['step_index'], fp2['step_index']))\n",
    " \n",
    "## Get the distances from PDR\n",
    "true_d = {}\n",
    "for step1 in traj['steps']:\n",
    "    for step2 in traj['steps']:\n",
    "        key = (step1['step_index'],step2['step_index'])\n",
    "        if key in keys:\n",
    "            true_d[key] = abs(step1['di'] - step2['di'])\n",
    "            \n",
    "    \n",
    "euc_d = {}\n",
    "man_d = {}\n",
    "for fp1 in traj['fps']:\n",
    "    for fp2 in traj['fps']:\n",
    "        key = (fp1['step_index'],fp2['step_index'])\n",
    "        if key in keys:\n",
    "            euc_d[key] = euclidean(fp1['profile'],fp2['profile'])\n",
    "            man_d[key] = manhattan(fp1['profile'],fp2['profile'])\n",
    "\n",
    "print(\"Euclidean Average Error\")\n",
    "print(f'{eval_dist_metric(euc_d, true_d):.2f}')\n",
    "\n",
    "print(\"Manhattan Average Error\")\n",
    "print(f'{eval_dist_metric(man_d, true_d):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you correctly implemented the functions you should have seen that the average error for the euclidean metric was `9.29` whilst the Manhattan was only `4.90`. So for this data, the Manhattan distance is a better estimate of the true distance. \n",
    "\n",
    "This is of course a very simplistic model. Indeed, there is no direct relationship between the RSSI values and the free space distance in this way. Typically, when we create our own estimates for distance we would use the known pdr distances from within a trajectory to fit the numeric score to a physical distance estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 WiFi Similarity Metric\n",
    "\n",
    "For your main challenge, we would like you to develop your own metric to estimate the real-world distance between two scans, based solely on their WiFi fingerprints. We will provide you with real crowdsourced data collected early in 2021 from a single mall. The data will contain 114661 fingerprints scans and 879824 distances between the scans. The distances will be our best estimate of the true distance given additional information that we will take into account. \n",
    "\n",
    "We will provide a test set of fingerprint pairs and you will need to write a function that tells us how far apart they are. \n",
    "\n",
    "This function could be as simple as a variation on one of the metrics that we introduced above or as complex as a full machine learning solution that learns to weight different mac addresses (or mac address combinations) differently in different situations.\n",
    "\n",
    "Some final points to consider:\n",
    "- lower RSSI values give less information.\n",
    "- Open spaces will have different WiFi characteristics than tight spaces\n",
    "- WiFi signals can be blocked by thick walls\n",
    "- A small number of MACs may be from moving emitters (people running a Hot-Spot on their phone)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Loading the data\n",
    "\n",
    "The data is assembled as three files for you.\n",
    "\n",
    "The `task1_fingerprints.json` contains all the fingerprint information for the problem. That is each entry represents a real scan of the WiFi emitters in an area of the mall. You will find that the same MAC addresses will be present in many of the fingerprints.\n",
    "\n",
    "The `task1_train.csv` contains the valid training pairs to help you design/train your algorithm. Each `id1-id2` pair has a labelled ground truth distance (in metres) and each id corresponds to a fingerprints from `task1_fingerprints.json`.\n",
    "\n",
    "The `task1_test.csv` is the same format as `task1_train.csv` but doesn't have the displacements included. These are what we would like you to predict using the raw fingerprint information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "879824it [00:03, 258319.79it/s]\n",
      "5160445it [00:16, 311885.48it/s]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "path_to_data = \"\"\n",
    "\n",
    "with open(os.path.join(path_to_data,\"task1_fingerprints.json\")) as f:\n",
    "    fps = json.load(f)\n",
    "    \n",
    "with open(os.path.join(path_to_data,\"task1_train.csv\")) as f:\n",
    "    train_data = []\n",
    "    train_h = csv.DictReader(f)\n",
    "    for pair in tqdm(train_h):\n",
    "        train_data.append([pair['id1'],pair['id2'],float(pair['displacement'])])\n",
    "        \n",
    "with open(os.path.join(path_to_data,\"task1_test.csv\")) as f:\n",
    "    test_h = csv.DictReader(f)\n",
    "    test_ids = []\n",
    "    for pair in tqdm(test_h):\n",
    "        test_ids.append([pair['id1'],pair['id2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 The Ideal Model\n",
    "\n",
    "Ultimately, the ideal model should be able to find an exact mapping between the highly dimensional fingerprint space (1 fingerprint can contain many measurements) and the 1 dimensional distance space. It can be useful to plot the pdr distance (from the training data) against some computed similarity metric to see if the metric reveals an obvious trend. High similarity should correlate with low distance.\n",
    "\n",
    "Below is one distance metric that we use internally for this task. You can see that even for this metric, we have a considerable amount of noise.\n",
    "\n",
    "**Due to this level of noise, our scoring metric for task 1 will be biased towards precision over recall**\n",
    "\n",
    "![sim_vs_pdr.png](figures/sim_vs_pdr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Submission\n",
    "\n",
    "Your submission should use the **exact** ids from the *test1_test.csv* file and should populate the third (currently empty) displacement column with your estimated distance (in metres) for that fingerprint pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_distance_function(fp1, fp2):\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = [[\"id1\", \"id2\", \"displacement\"]]\n",
    "for id1, id2 in tqdm(test_ids):\n",
    "    fp1 = fps[id1]\n",
    "    fp2 = fps[id2]\n",
    "    \n",
    "    distance_estimate = my_distance_function(fp1,fp2)\n",
    "    output_data.append([id1,id2,distance_estimate])\n",
    "    \n",
    "with open(\"MySubmission.csv\", \"w\", newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![graph_2.png](figures/trigraph_2.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
